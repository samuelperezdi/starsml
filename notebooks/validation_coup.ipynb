{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from astropy.coordinates import SkyCoord\n",
    "from astropy import units as u\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "import os\n",
    "from src.classification import get_match_label_simple\n",
    "from src.data import get_data_basic_matches\n",
    "from sklearn.model_selection import train_test_split\n",
    "from src.utils import transform_features, normalize_train_test\n",
    "\n",
    "from joblib import load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_model = pd.read_parquet('../scripts/nway_csc21_gaia3_full_neg_study_dis_niter200.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark_ids = load('../scripts/jobs/models/neg_study_dis_niter200_withint_with_int_5X_lgbm_0-3_20241113_235113/benchmark_ids.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Range 0-3: 30279 positives, 310020 negatives\n",
      "Range 0-3: 24223 positives, 245627 negatives\n",
      "Range 0-3: 19378 positives, 195135 negatives\n",
      "Range 0-3: 4845 positives, 50492 negatives\n",
      "Range 0-3: 6056 positives, 64393 negatives\n"
     ]
    }
   ],
   "source": [
    "def get_train_val_test_splits(df_all_model, benchmark_ids, range_offaxis='0-3', separation=1.3):\n",
    "   # get initial positives and split test set\n",
    "   df_pos, _ = get_data_basic_matches(df_all_model, range_offaxis, separation)\n",
    "   cscids = df_pos['csc21_name'].unique()\n",
    "   cscids_train_val, cscids_test = train_test_split(cscids, test_size=0.2, random_state=42)\n",
    "   \n",
    "   # get train/val split from filtered train_val data\n",
    "   df_train_val = df_all_model[df_all_model['csc21_name'].isin(cscids_train_val)]\n",
    "   train_pos, _ = get_data_basic_matches(df_train_val, range_offaxis, separation)\n",
    "   train_val_cscids = train_pos['csc21_name'].unique()\n",
    "   cscids_train, cscids_val = train_test_split(train_val_cscids, test_size=0.2, random_state=42)\n",
    "   \n",
    "   assert set(benchmark_ids) == set(cscids_test)\n",
    "   \n",
    "   # get final datasets\n",
    "   splits = {}\n",
    "   for name, ids in [('train', cscids_train), ('val', cscids_val), ('test', cscids_test)]:\n",
    "       data = df_all_model[df_all_model['csc21_name'].isin(ids)]\n",
    "       pos, neg = get_data_basic_matches(data, range_offaxis, separation)\n",
    "       splits[name] = {'pos': pos, 'neg': neg, 'full': data}\n",
    "       \n",
    "   return splits\n",
    "\n",
    "splits = get_train_val_test_splits(df_all_model, benchmark_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_949047/694336655.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  val_data['eval_label'] = np.where(val_data['match_flag'] == 1, 1, 0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def validate_splits(splits, model_path):\n",
    "   \"\"\"validate train/val splits match saved model data\"\"\"\n",
    "   \n",
    "   # combine pos/neg sets\n",
    "   val_data = splits['val']['full']\n",
    "   train_data = splits['train']['full']\n",
    "   \n",
    "   # load saved validation data\n",
    "   X_eval_saved = load(os.path.join(model_path, 'X_eval.joblib'))\n",
    "   y_eval_saved = load(os.path.join(model_path, 'y_eval.joblib'))\n",
    "   \n",
    "   # prepare validation data\n",
    "   val_data['eval_label'] = np.where(val_data['match_flag'] == 1, 1, 0)\n",
    "   \n",
    "   # preprocess\n",
    "   X_train, _ = transform_features(train_data, log_transform=False, model_type='lgbm')\n",
    "   X_val, cat_features = transform_features(val_data, log_transform=False, model_type='lgbm')\n",
    "   _, X_val_norm, _ = normalize_train_test(X_train, X_val, method='none', \n",
    "                                         categorical_features=cat_features)\n",
    "   \n",
    "   # verify\n",
    "   assert X_eval_saved.equals(X_val_norm)\n",
    "   assert np.array_equal(y_eval_saved, val_data['eval_label'].values)\n",
    "   \n",
    "   return True\n",
    "\n",
    "validate_splits(splits, '../scripts/jobs/models/neg_study_dis_niter200_withint_with_int_5X_lgbm_0-3_20241113_235113')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the test data + everything from the dataset that was not in train and val\n",
    "test_data = splits['test']['full']\n",
    "\n",
    "# now get everything that was not in train and val\n",
    "train_val_data = pd.concat([splits['train']['full'], splits['val']['full']])\n",
    "train_val_ids = train_val_data['csc21_name'].unique()\n",
    "not_train_val_data = df_all_model[~df_all_model['csc21_name'].isin(train_val_ids)].copy()\n",
    "\n",
    "# check if test is IN not_train_val_data\n",
    "assert set(test_data['csc21_name'].unique()) <= set(not_train_val_data['csc21_name'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the center of the Orion Nebula region\n",
    "orion_center = SkyCoord(ra=83.8210 * u.deg, dec=-5.3944 * u.deg, frame='icrs')\n",
    "\n",
    "# Create SkyCoord objects for all sources\n",
    "orion_source_coords = SkyCoord(ra=df_all_model['csc21_ra'].values * u.deg, dec=df_all_model['csc21_dec'].values * u.deg, frame='icrs')\n",
    "\n",
    "# Calculate separations\n",
    "orion_separations = orion_source_coords.separation(orion_center).to(u.arcmin)\n",
    "\n",
    "# Filter the dataframe\n",
    "df_all_model['separation_from_orion'] = orion_separations\n",
    "orion_sources_in_region = df_all_model[orion_separations <= 30 * u.arcmin].copy()\n",
    "orion_cscid_list = orion_sources_in_region['csc21_name'].str.replace('_', ' ').str.strip().unique().tolist()\n",
    "orion_sources_in_region['num_possible_counterparts'] = orion_sources_in_region.groupby('csc21_name')['gaia3_source_id'].transform('count')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_in_crit = get_match_label_simple(orion_sources_in_region, p_threshold=0.35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_in_crit_test_and_more = df_in_crit[df_in_crit['csc21_name'].isin(not_train_val_data['csc21_name'].unique())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1412"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_in_crit_test_and_more.csc21_name.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    3723.000000\n",
       "mean        3.873243\n",
       "std         3.295419\n",
       "min         0.028973\n",
       "25%         1.333459\n",
       "50%         3.074227\n",
       "75%         5.609001\n",
       "max        21.031032\n",
       "Name: min_theta_mean, dtype: float64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_in_crit_test_and_more['min_theta_mean'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>csc21_name</th>\n",
       "      <th>separation</th>\n",
       "      <th>p_i</th>\n",
       "      <th>p_any</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1058146</th>\n",
       "      <td>2CXO J053517.0-052339</td>\n",
       "      <td>0.005774</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1054744</th>\n",
       "      <td>2CXO J053446.9-053414</td>\n",
       "      <td>0.008453</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1058743</th>\n",
       "      <td>2CXO J053518.4-052329</td>\n",
       "      <td>0.014907</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1059376</th>\n",
       "      <td>2CXO J053521.2-052457</td>\n",
       "      <td>0.015802</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1058133</th>\n",
       "      <td>2CXO J053517.0-052333</td>\n",
       "      <td>0.020119</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1058385</th>\n",
       "      <td>2CXO J053517.6-052153</td>\n",
       "      <td>0.022458</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1058357</th>\n",
       "      <td>2CXO J053517.5-052256</td>\n",
       "      <td>0.022656</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1059865</th>\n",
       "      <td>2CXO J053525.0-052258</td>\n",
       "      <td>0.023547</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1059800</th>\n",
       "      <td>2CXO J053524.1-052155</td>\n",
       "      <td>0.024223</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1058807</th>\n",
       "      <td>2CXO J053518.6-052313</td>\n",
       "      <td>0.024504</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999898</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    csc21_name  separation  p_i     p_any\n",
       "1058146  2CXO J053517.0-052339    0.005774  1.0  0.999904\n",
       "1054744  2CXO J053446.9-053414    0.008453  1.0  0.999904\n",
       "1058743  2CXO J053518.4-052329    0.014907  1.0  0.999896\n",
       "1059376  2CXO J053521.2-052457    0.015802  1.0  0.999904\n",
       "1058133  2CXO J053517.0-052333    0.020119  1.0  0.999897\n",
       "1058385  2CXO J053517.6-052153    0.022458  1.0  0.999899\n",
       "1058357  2CXO J053517.5-052256    0.022656  1.0  0.999903\n",
       "1059865  2CXO J053525.0-052258    0.023547  1.0  0.999902\n",
       "1059800  2CXO J053524.1-052155    0.024223  1.0  0.999896\n",
       "1058807  2CXO J053518.6-052313    0.024504  1.0  0.999898"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_in_crit_test_and_more.query('min_theta_mean < 3').sort_values('separation').head(10)[['csc21_name', 'separation', 'p_i', 'p_any']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if all the cases with min_theta_mean < 3 and separation <1.3 are in the test set\n",
    "\n",
    "assert set(df_in_crit_test_and_more.query('min_theta_mean < 3 and separation<1.3 and p_any>0.9')['csc21_name'].unique()) <= set(test_data['csc21_name'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_performance_table(df):\n",
    "   \"\"\"create performance metrics and tabular summary\"\"\"\n",
    "   total_sources = df['csc21_name'].nunique()\n",
    "   \n",
    "   match_cases = {\n",
    "       'total_sources': total_sources,\n",
    "       'contains_match': {'count': 0, 'pct': 0},\n",
    "       'exact_match': {'count': 0, 'pct': 0}, \n",
    "       'different': {'count': 0, 'pct': 0},\n",
    "       'no_match': {'count': 0, 'pct': 0},\n",
    "       'multiple': {'count': 0, 'pct': 0}\n",
    "   }\n",
    "\n",
    "   for _, group in df.groupby('csc21_name'):\n",
    "       ml_matches = group[group['label'] == 1]\n",
    "       nway_matches = group[group['match_flag'] == 1]\n",
    "       \n",
    "       if len(nway_matches) == 1:\n",
    "           if nway_matches.index.isin(ml_matches.index).all():\n",
    "               match_cases['contains_match']['count'] += 1\n",
    "       if len(ml_matches) == 1 and len(nway_matches) == 1:\n",
    "           if ml_matches.index.equals(nway_matches.index):\n",
    "               match_cases['exact_match']['count'] += 1\n",
    "           else:\n",
    "               match_cases['different']['count'] += 1\n",
    "       elif len(ml_matches) == 0:\n",
    "           match_cases['no_match']['count'] += 1\n",
    "       elif len(ml_matches) > 1:\n",
    "           match_cases['multiple']['count'] += 1\n",
    "           \n",
    "   for key in match_cases:\n",
    "       if key != 'total_sources':\n",
    "           match_cases[key]['pct'] = (\n",
    "               match_cases[key]['count'] / total_sources * 100\n",
    "           )\n",
    "   \n",
    "   table = f\"\"\"\n",
    "Performance Summary (N={total_sources})\n",
    "=====================================\n",
    "Category          Count    Percent\n",
    "-------------------------------------\n",
    "Contains Match    {match_cases['contains_match']['count']:>5}     {match_cases['contains_match']['pct']:>6.1f}%\n",
    "Exact Match      {match_cases['exact_match']['count']:>5}     {match_cases['exact_match']['pct']:>6.1f}%\n",
    "Different Match  {match_cases['different']['count']:>5}     {match_cases['different']['pct']:>6.1f}%\n",
    "No Match         {match_cases['no_match']['count']:>5}     {match_cases['no_match']['pct']:>6.1f}%\n",
    "Multiple         {match_cases['multiple']['count']:>5}     {match_cases['multiple']['pct']:>6.1f}%\n",
    "\"\"\"\n",
    "   \n",
    "   return match_cases, table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Performance Summary (N=1412)\n",
      "=====================================\n",
      "Category          Count    Percent\n",
      "-------------------------------------\n",
      "Contains Match      990       70.1%\n",
      "Exact Match        950       67.3%\n",
      "Different Match      6        0.4%\n",
      "No Match           416       29.5%\n",
      "Multiple            40        2.8%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stats, email = create_performance_table(df_in_crit_test_and_more)\n",
    "print(email)  # for quick review\n",
    "# or stats for detailed analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_performance_metrics(df):\n",
    "   \"\"\"compute match statistics between nway and ml model\"\"\"\n",
    "   metrics = {}\n",
    "   \n",
    "   # base counts\n",
    "   metrics['N_CSC'] = df['csc21_name'].nunique()\n",
    "   metrics['N_yNWAY'] = df[df['p_any'] > 0.5]['csc21_name'].nunique()\n",
    "   \n",
    "   # combined criteria using label column\n",
    "   ok_matches = (df['p_any'] > 0.5) & (df['label'] == 1)\n",
    "   metrics['N_OK'] = df[ok_matches]['csc21_name'].nunique()\n",
    "   \n",
    "   no_ml = (df['p_any'] > 0.5) & ~df.groupby('csc21_name')['label'].transform(any)\n",
    "   metrics['N_NoML'] = df[no_ml]['csc21_name'].nunique()\n",
    "   \n",
    "   flip = (df['p_any'] <= 0.5) & (df['label'] == 1)\n",
    "   metrics['N_FLIP'] = df[flip]['csc21_name'].nunique()\n",
    "   \n",
    "   none = (df['p_any'] <= 0.5) & ~df.groupby('csc21_name')['label'].transform(any)\n",
    "   metrics['N_NONE'] = df[none]['csc21_name'].nunique()\n",
    "   \n",
    "   # single/multiple match counts \n",
    "   ok_single = ok_matches & (df.groupby('csc21_name')['label'].transform(sum) == 1)\n",
    "   metrics['N_yNWAY+yMLeq1'] = df[ok_single]['csc21_name'].nunique()\n",
    "   metrics['N_yNWAY+yMLgt1'] = metrics['N_OK'] - metrics['N_yNWAY+yMLeq1']\n",
    "   \n",
    "   flip_single = flip & (df.groupby('csc21_name')['label'].transform(sum) == 1)\n",
    "   metrics['N_FLIPeq1'] = df[flip_single]['csc21_name'].nunique()\n",
    "   metrics['N_FLIPgt1'] = metrics['N_FLIP'] - metrics['N_FLIPeq1']\n",
    "\n",
    "   table = f\"\"\"\n",
    "N_CSC = {metrics['N_CSC']}\n",
    "N_yNWAY = {metrics['N_yNWAY']}\n",
    "N_OK = {metrics['N_OK']}\n",
    "N_NoML = {metrics['N_NoML']}\n",
    "N_FLIP = {metrics['N_FLIP']}\n",
    "N_NONE = {metrics['N_NONE']}\n",
    "N_yNWAY+yMLeq1 = {metrics['N_yNWAY+yMLeq1']}\n",
    "N_yNWAY+yMLgt1 = {metrics['N_yNWAY+yMLgt1']}\n",
    "N_FLIPeq1 = {metrics['N_FLIPeq1']}\n",
    "N_FLIPgt1 = {metrics['N_FLIPgt1']}\n",
    "\"\"\"\n",
    "   \n",
    "   return metrics, table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_949047/103789065.py:23: FutureWarning: The provided callable <built-in function sum> is currently using SeriesGroupBy.sum. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"sum\" instead.\n",
      "  ok_single = ok_matches & (df.groupby('csc21_name')['label'].transform(sum) == 1)\n",
      "/tmp/ipykernel_949047/103789065.py:27: FutureWarning: The provided callable <built-in function sum> is currently using SeriesGroupBy.sum. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"sum\" instead.\n",
      "  flip_single = flip & (df.groupby('csc21_name')['label'].transform(sum) == 1)\n"
     ]
    }
   ],
   "source": [
    "stats_vk, email_vk = create_performance_metrics(df_in_crit_test_and_more)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "N_CSC = 1412\n",
      "N_yNWAY = 1006\n",
      "N_OK = 952\n",
      "N_NoML = 54\n",
      "N_FLIP = 44\n",
      "N_NONE = 362\n",
      "N_yNWAY+yMLeq1 = 920\n",
      "N_yNWAY+yMLgt1 = 32\n",
      "N_FLIPeq1 = 36\n",
      "N_FLIPgt1 = 8\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(email_vk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_matches(df, df_all_stacks, threshold):\n",
    "   \"\"\"analyze match cases and output standardized csvs:\n",
    "   coup_nway1_mlX_tr{threshold}: no match by ML  \n",
    "   coup_nway1_ml1M_tr{threshold}: multiple matches by ML\n",
    "   coup_nway1_mlneq0_tr{threshold}: different match by ML\"\"\"\n",
    "   \n",
    "   output_cols = [\n",
    "       'csc21_name', 'csc21_ra', 'csc21_dec', 'min_theta_mean',\n",
    "       'detect_stack_id', 'gaia3_source_id', 'p_i', 'p_any', \n",
    "       'p_match_ind', 'separation', 'match_flag', 'label', 'phot_g_mean_mag',\n",
    "       'phot_bp_mean_mag', 'phot_rp_mean_mag', 'bp_rp'\n",
    "   ]\n",
    "   \n",
    "   result = {}\n",
    "   different_matches = []\n",
    "   no_counterparts = []\n",
    "   multiple_matches = []\n",
    "   \n",
    "   for csc_id, group in df.groupby('csc21_name'):\n",
    "       label_matches = group[group['label'] == 1]\n",
    "       nway_matches = group[group['match_flag'] == 1]\n",
    "       \n",
    "       if len(label_matches) == 1 and len(nway_matches) == 1:\n",
    "           if not label_matches.index.equals(nway_matches.index):\n",
    "               different_matches.append(group)\n",
    "       elif len(label_matches) == 0:\n",
    "           no_counterparts.append(group)\n",
    "       elif len(label_matches) > 1:\n",
    "           multiple_matches.append(group)\n",
    "\n",
    "   # map keys to filenames\n",
    "   filenames = {\n",
    "       'different_matches': f'coup_nway1_mlneq0_tr{threshold}',\n",
    "       'no_counterparts': f'coup_nway1_mlX_tr{threshold}',\n",
    "       'multiple_matches': f'coup_nway1_ml1M_tr{threshold}'\n",
    "   }\n",
    "   \n",
    "   for key, data in zip(\n",
    "       ['different_matches', 'no_counterparts', 'multiple_matches'],\n",
    "       [different_matches, no_counterparts, multiple_matches]\n",
    "   ):\n",
    "       if data:\n",
    "           df_merged = (pd.concat(data)\n",
    "                       .merge(df_all_stacks[['name', 'detect_stack_id']],\n",
    "                              left_on='csc21_name', right_on='name', how='left')\n",
    "                       [output_cols])\n",
    "           #df_merged.to_csv(f'outputs/{filenames[key]}.csv', index=False)\n",
    "           result[key] = df_merged\n",
    "\n",
    "   result['summary'] = {\n",
    "       'different_matches': len(set(result['different_matches']['csc21_name'])),\n",
    "       'no_counterparts': len(set(result['no_counterparts']['csc21_name'])),\n",
    "       'multiple_matches': len(set(result['multiple_matches']['csc21_name']))\n",
    "   }\n",
    "   \n",
    "   return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read vot to pandas ../data/all_stacks.vot\n",
    "from astropy.io.votable import parse_single_table\n",
    "\n",
    "# read vot to pandas\n",
    "table = parse_single_table('../data/all_stacks.vot')\n",
    "\n",
    "# recover column names\n",
    "df_all_stacks = table.to_table().to_pandas()\n",
    "df_all_stacks.columns = [col.name for col in table.fields]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_discrepant = analyze_matches(df_in_crit_test_and_more, df_all_stacks, threshold=0.35)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
