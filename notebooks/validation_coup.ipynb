{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from astropy.coordinates import SkyCoord\n",
    "from astropy import units as u\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "import os\n",
    "from src.classification import get_match_label_simple\n",
    "from src.data import get_data_basic_matches\n",
    "from sklearn.model_selection import train_test_split\n",
    "from src.utils import transform_features, normalize_train_test\n",
    "\n",
    "from joblib import load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_model = pd.read_parquet('../scripts/nway_csc21_gaia3_full_neg_study_dis_niter200.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark_ids = load('../scripts/jobs/models/neg_study_dis_niter200_withint_with_int_5X_lgbm_0-3_20241113_235113/benchmark_ids.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Range 0-3: 30279 positives, 310020 negatives\n",
      "Range 0-3: 24223 positives, 245627 negatives\n",
      "Range 0-3: 19378 positives, 195135 negatives\n",
      "Range 0-3: 4845 positives, 50492 negatives\n",
      "Range 0-3: 6056 positives, 64393 negatives\n"
     ]
    }
   ],
   "source": [
    "def get_train_val_test_splits(df_all_model, benchmark_ids, range_offaxis='0-3', separation=1.3):\n",
    "   # get initial positives and split test set\n",
    "   df_pos, _ = get_data_basic_matches(df_all_model, range_offaxis, separation)\n",
    "   cscids = df_pos['csc21_name'].unique()\n",
    "   cscids_train_val, cscids_test = train_test_split(cscids, test_size=0.2, random_state=42)\n",
    "   \n",
    "   # get train/val split from filtered train_val data\n",
    "   df_train_val = df_all_model[df_all_model['csc21_name'].isin(cscids_train_val)]\n",
    "   train_pos, _ = get_data_basic_matches(df_train_val, range_offaxis, separation)\n",
    "   train_val_cscids = train_pos['csc21_name'].unique()\n",
    "   cscids_train, cscids_val = train_test_split(train_val_cscids, test_size=0.2, random_state=42)\n",
    "   \n",
    "   assert set(benchmark_ids) == set(cscids_test)\n",
    "   \n",
    "   # get final datasets\n",
    "   splits = {}\n",
    "   for name, ids in [('train', cscids_train), ('val', cscids_val), ('test', cscids_test)]:\n",
    "       data = df_all_model[df_all_model['csc21_name'].isin(ids)]\n",
    "       pos, neg = get_data_basic_matches(data, range_offaxis, separation)\n",
    "       splits[name] = {'pos': pos, 'neg': neg, 'full': data}\n",
    "       \n",
    "   return splits\n",
    "\n",
    "splits = get_train_val_test_splits(df_all_model, benchmark_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1966374/694336655.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  val_data['eval_label'] = np.where(val_data['match_flag'] == 1, 1, 0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def validate_splits(splits, model_path):\n",
    "   \"\"\"validate train/val splits match saved model data\"\"\"\n",
    "   \n",
    "   # combine pos/neg sets\n",
    "   val_data = splits['val']['full']\n",
    "   train_data = splits['train']['full']\n",
    "   \n",
    "   # load saved validation data\n",
    "   X_eval_saved = load(os.path.join(model_path, 'X_eval.joblib'))\n",
    "   y_eval_saved = load(os.path.join(model_path, 'y_eval.joblib'))\n",
    "   \n",
    "   # prepare validation data\n",
    "   val_data['eval_label'] = np.where(val_data['match_flag'] == 1, 1, 0)\n",
    "   \n",
    "   # preprocess\n",
    "   X_train, _ = transform_features(train_data, log_transform=False, model_type='lgbm')\n",
    "   X_val, cat_features = transform_features(val_data, log_transform=False, model_type='lgbm')\n",
    "   _, X_val_norm, _ = normalize_train_test(X_train, X_val, method='none', \n",
    "                                         categorical_features=cat_features)\n",
    "   \n",
    "   # verify\n",
    "   assert X_eval_saved.equals(X_val_norm)\n",
    "   assert np.array_equal(y_eval_saved, val_data['eval_label'].values)\n",
    "   \n",
    "   return True\n",
    "\n",
    "validate_splits(splits, '../scripts/jobs/models/neg_study_dis_niter200_withint_with_int_5X_lgbm_0-3_20241113_235113')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the test data + everything from the dataset that was not in train and val\n",
    "test_data = splits['test']['full']\n",
    "\n",
    "# now get everything that was not in train and val\n",
    "train_val_data = pd.concat([splits['train']['full'], splits['val']['full']])\n",
    "train_val_ids = train_val_data['csc21_name'].unique()\n",
    "not_train_val_data = df_all_model[~df_all_model['csc21_name'].isin(train_val_ids)].copy()\n",
    "\n",
    "# check if test is IN not_train_val_data\n",
    "assert set(test_data['csc21_name'].unique()) <= set(not_train_val_data['csc21_name'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the center of the Orion Nebula region\n",
    "orion_center = SkyCoord(ra=83.8210 * u.deg, dec=-5.3944 * u.deg, frame='icrs')\n",
    "\n",
    "# Create SkyCoord objects for all sources\n",
    "orion_source_coords = SkyCoord(ra=df_all_model['csc21_ra'].values * u.deg, dec=df_all_model['csc21_dec'].values * u.deg, frame='icrs')\n",
    "\n",
    "# Calculate separations\n",
    "orion_separations = orion_source_coords.separation(orion_center).to(u.arcmin)\n",
    "\n",
    "# Filter the dataframe\n",
    "df_all_model['separation_from_orion'] = orion_separations\n",
    "orion_sources_in_region = df_all_model[orion_separations <= 30 * u.arcmin].copy()\n",
    "orion_cscid_list = orion_sources_in_region['csc21_name'].str.replace('_', ' ').str.strip().unique().tolist()\n",
    "orion_sources_in_region['num_possible_counterparts'] = orion_sources_in_region.groupby('csc21_name')['gaia3_source_id'].transform('count')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_in_crit = get_match_label_simple(orion_sources_in_region, p_threshold=0.35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_in_crit_test_and_more = df_in_crit[df_in_crit['csc21_name'].isin(not_train_val_data['csc21_name'].unique())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1412"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_in_crit_test_and_more.csc21_name.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if all the cases with min_theta_mean < 3 and separation <1.3 are in the test set\n",
    "\n",
    "assert set(df_in_crit_test_and_more.query('min_theta_mean < 3 and separation<1.3 and p_any>0.9')['csc21_name'].unique()) <= set(test_data['csc21_name'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_performance_metrics(df):\n",
    "   \"\"\"compute match statistics between nway and ml model\"\"\"\n",
    "   metrics = {}\n",
    "   \n",
    "   # base counts\n",
    "   metrics['N_CSC'] = df['csc21_name'].nunique()\n",
    "   metrics['N_yNWAY'] = df[df['p_any'] > 0.5]['csc21_name'].nunique()\n",
    "   \n",
    "   # combined criteria using label column\n",
    "   ok_matches = (df['p_any'] > 0.5) & (df['label'] == 1)\n",
    "   metrics['N_OK'] = df[ok_matches]['csc21_name'].nunique()\n",
    "   \n",
    "   no_ml = (df['p_any'] > 0.5) & ~df.groupby('csc21_name')['label'].transform(any)\n",
    "   metrics['N_NoML'] = df[no_ml]['csc21_name'].nunique()\n",
    "   \n",
    "   flip = (df['p_any'] <= 0.5) & (df['label'] == 1)\n",
    "   metrics['N_FLIP'] = df[flip]['csc21_name'].nunique()\n",
    "   \n",
    "   none = (df['p_any'] <= 0.5) & ~df.groupby('csc21_name')['label'].transform(any)\n",
    "   metrics['N_NONE'] = df[none]['csc21_name'].nunique()\n",
    "   \n",
    "   # single/multiple match counts \n",
    "   ok_single = ok_matches & (df.groupby('csc21_name')['label'].transform(sum) == 1)\n",
    "   metrics['N_yNWAY+yMLeq1'] = df[ok_single]['csc21_name'].nunique()\n",
    "   metrics['N_yNWAY+yMLgt1'] = metrics['N_OK'] - metrics['N_yNWAY+yMLeq1']\n",
    "   \n",
    "   flip_single = flip & (df.groupby('csc21_name')['label'].transform(sum) == 1)\n",
    "   metrics['N_FLIPeq1'] = df[flip_single]['csc21_name'].nunique()\n",
    "   metrics['N_FLIPgt1'] = metrics['N_FLIP'] - metrics['N_FLIPeq1']\n",
    "\n",
    "   table = f\"\"\"\n",
    "N_CSC = {metrics['N_CSC']}\n",
    "N_yNWAY = {metrics['N_yNWAY']}\n",
    "N_OK = {metrics['N_OK']}\n",
    "N_NoML = {metrics['N_NoML']}\n",
    "N_FLIP = {metrics['N_FLIP']}\n",
    "N_NONE = {metrics['N_NONE']}\n",
    "N_yNWAY+yMLeq1 = {metrics['N_yNWAY+yMLeq1']}\n",
    "N_yNWAY+yMLgt1 = {metrics['N_yNWAY+yMLgt1']}\n",
    "N_FLIPeq1 = {metrics['N_FLIPeq1']}\n",
    "N_FLIPgt1 = {metrics['N_FLIPgt1']}\n",
    "\"\"\"\n",
    "   \n",
    "   return metrics, table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "N_CSC = 1412\n",
      "N_yNWAY = 1006\n",
      "N_OK = 952\n",
      "N_NoML = 54\n",
      "N_FLIP = 44\n",
      "N_NONE = 362\n",
      "N_yNWAY+yMLeq1 = 920\n",
      "N_yNWAY+yMLgt1 = 32\n",
      "N_FLIPeq1 = 36\n",
      "N_FLIPgt1 = 8\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1966374/103789065.py:23: FutureWarning: The provided callable <built-in function sum> is currently using SeriesGroupBy.sum. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"sum\" instead.\n",
      "  ok_single = ok_matches & (df.groupby('csc21_name')['label'].transform(sum) == 1)\n",
      "/tmp/ipykernel_1966374/103789065.py:27: FutureWarning: The provided callable <built-in function sum> is currently using SeriesGroupBy.sum. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"sum\" instead.\n",
      "  flip_single = flip & (df.groupby('csc21_name')['label'].transform(sum) == 1)\n"
     ]
    }
   ],
   "source": [
    "stats_vk, email_vk = create_performance_metrics(df_in_crit_test_and_more)\n",
    "\n",
    "print(email_vk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gaia_multiple_n(df):\n",
    "   \"\"\"count total gaia matches in multiple match cases\"\"\"\n",
    "   # get sources with multiple matches\n",
    "   ok_multiples = (df['p_any'] > 0.5) & (df.groupby('csc21_name')['label'].transform(sum) > 1)\n",
    "   flip_multiples = (df['p_any'] <= 0.5) & (df.groupby('csc21_name')['label'].transform(sum) > 1)\n",
    "\n",
    "   # count matches\n",
    "   n_ok_gaia = df[ok_multiples & (df['label'] == 1)]['gaia3_source_id'].nunique()\n",
    "   n_flip_gaia = df[flip_multiples & (df['label'] == 1)]['gaia3_source_id'].nunique()\n",
    "   \n",
    "   return {\n",
    "       'N_yNWAY+yMLgt1_gaia': n_ok_gaia,\n",
    "       'N_FLIPgt1_gaia': n_flip_gaia\n",
    "   }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1966374/3518964572.py:4: FutureWarning: The provided callable <built-in function sum> is currently using SeriesGroupBy.sum. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"sum\" instead.\n",
      "  ok_multiples = (df['p_any'] > 0.5) & (df.groupby('csc21_name')['label'].transform(sum) > 1)\n",
      "/tmp/ipykernel_1966374/3518964572.py:5: FutureWarning: The provided callable <built-in function sum> is currently using SeriesGroupBy.sum. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"sum\" instead.\n",
      "  flip_multiples = (df['p_any'] <= 0.5) & (df.groupby('csc21_name')['label'].transform(sum) > 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'N_yNWAY+yMLgt1_gaia': 65, 'N_FLIPgt1_gaia': 16}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_gaia_multiple_n(df_in_crit_test_and_more)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_match_cases(df, df_all_stacks):\n",
    "   \"\"\"export csvs for each match case type\"\"\"\n",
    "   output_cols = [\n",
    "       'csc21_name', 'csc21_ra', 'csc21_dec', 'min_theta_mean',\n",
    "       'detect_stack_id', 'gaia3_source_id', 'p_i', 'p_any', \n",
    "       'p_match_ind', 'separation', 'match_flag', 'label',\n",
    "       'phot_g_mean_mag', 'phot_bp_mean_mag', 'phot_rp_mean_mag', 'bp_rp'\n",
    "   ]\n",
    "\n",
    "   # initialize cases\n",
    "   N_yNWAY = []\n",
    "   N_OK = []\n",
    "   N_NoML = [] \n",
    "   N_FLIP = []\n",
    "   N_NONE = []\n",
    "   \n",
    "   for csc_id, group in df.groupby('csc21_name'):\n",
    "       nway_confident = group['p_any'].max() > 0.5\n",
    "       ml_matches = group[group['label'] == 1]\n",
    "       \n",
    "       if nway_confident:\n",
    "           N_yNWAY.append(group)\n",
    "           if len(ml_matches) > 0:\n",
    "               N_OK.append(group)\n",
    "           else:\n",
    "               N_NoML.append(group)\n",
    "       else:\n",
    "           if len(ml_matches) > 0:\n",
    "               N_FLIP.append(group)\n",
    "           else:\n",
    "               N_NONE.append(group)\n",
    "   \n",
    "   # save cases to csv\n",
    "   cases = {\n",
    "       'N_yNWAY': N_yNWAY,\n",
    "       'N_OK': N_OK,\n",
    "       'N_NoML': N_NoML,\n",
    "       'N_FLIP': N_FLIP,\n",
    "       'N_NONE': N_NONE\n",
    "   }\n",
    "   \n",
    "   for case_name, case_data in cases.items():\n",
    "       if case_data:\n",
    "           df_case = (pd.concat(case_data)\n",
    "                     .merge(df_all_stacks[['name', 'detect_stack_id']], \n",
    "                           left_on='csc21_name', right_on='name', \n",
    "                           how='left')\n",
    "                     [output_cols])\n",
    "           df_case.to_csv(f'outputs/coup_{case_name}_trs0.35.csv', index=False)\n",
    "           \n",
    "   return {k: len(set(pd.concat(v)['csc21_name'])) if v else 0 \n",
    "           for k,v in cases.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read vot to pandas ../data/all_stacks.vot\n",
    "from astropy.io.votable import parse_single_table\n",
    "\n",
    "# read vot to pandas\n",
    "table = parse_single_table('../data/all_stacks.vot')\n",
    "\n",
    "# recover column names\n",
    "df_all_stacks = table.to_table().to_pandas()\n",
    "df_all_stacks.columns = [col.name for col in table.fields]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_discrepant = analyze_match_cases(df_in_crit_test_and_more, df_all_stacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'N_yNWAY': 1006, 'N_OK': 952, 'N_NoML': 54, 'N_FLIP': 44, 'N_NONE': 362}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_discrepant"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
