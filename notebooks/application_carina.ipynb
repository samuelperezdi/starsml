{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from astropy.coordinates import SkyCoord\n",
    "from astropy import units as u\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "import os\n",
    "from src.classification import get_match_label_simple\n",
    "from src.data import get_data_basic_matches\n",
    "from sklearn.model_selection import train_test_split\n",
    "from src.utils import transform_features, normalize_train_test\n",
    "\n",
    "from joblib import load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the whole dataset with probabilities generated by the model\n",
    "df_all_model = pd.read_parquet('../scripts/nway_csc21_gaia3_full_neg_study_dis_niter200.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark_ids = load('../scripts/jobs/models/neg_study_dis_niter200_withint_with_int_5X_lgbm_0-3_20241113_235113/benchmark_ids.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Range 0-3: 30279 positives, 310020 negatives\n",
      "Range 0-3: 24223 positives, 245627 negatives\n",
      "Range 0-3: 19378 positives, 195135 negatives\n",
      "Range 0-3: 4845 positives, 50492 negatives\n",
      "Range 0-3: 6056 positives, 64393 negatives\n"
     ]
    }
   ],
   "source": [
    "def get_train_val_test_splits(df_all_model, benchmark_ids, range_offaxis='0-3', separation=1.3):\n",
    "   # get initial positives and split test set\n",
    "   df_pos, _ = get_data_basic_matches(df_all_model, range_offaxis, separation)\n",
    "   cscids = df_pos['csc21_name'].unique()\n",
    "   cscids_train_val, cscids_test = train_test_split(cscids, test_size=0.2, random_state=42)\n",
    "   \n",
    "   # get train/val split from filtered train_val data\n",
    "   df_train_val = df_all_model[df_all_model['csc21_name'].isin(cscids_train_val)]\n",
    "   train_pos, _ = get_data_basic_matches(df_train_val, range_offaxis, separation)\n",
    "   train_val_cscids = train_pos['csc21_name'].unique()\n",
    "   cscids_train, cscids_val = train_test_split(train_val_cscids, test_size=0.2, random_state=42)\n",
    "   \n",
    "   assert set(benchmark_ids) == set(cscids_test)\n",
    "   \n",
    "   # get final datasets\n",
    "   splits = {}\n",
    "   for name, ids in [('train', cscids_train), ('val', cscids_val), ('test', cscids_test)]:\n",
    "       data = df_all_model[df_all_model['csc21_name'].isin(ids)]\n",
    "       pos, neg = get_data_basic_matches(data, range_offaxis, separation)\n",
    "       splits[name] = {'pos': pos, 'neg': neg, 'full': data}\n",
    "       \n",
    "   return splits\n",
    "\n",
    "splits = get_train_val_test_splits(df_all_model, benchmark_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_962181/694336655.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  val_data['eval_label'] = np.where(val_data['match_flag'] == 1, 1, 0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def validate_splits(splits, model_path):\n",
    "   \"\"\"validate train/val splits match saved model data\"\"\"\n",
    "   \n",
    "   # combine pos/neg sets\n",
    "   val_data = splits['val']['full']\n",
    "   train_data = splits['train']['full']\n",
    "   \n",
    "   # load saved validation data\n",
    "   X_eval_saved = load(os.path.join(model_path, 'X_eval.joblib'))\n",
    "   y_eval_saved = load(os.path.join(model_path, 'y_eval.joblib'))\n",
    "   \n",
    "   # prepare validation data\n",
    "   val_data['eval_label'] = np.where(val_data['match_flag'] == 1, 1, 0)\n",
    "   \n",
    "   # preprocess\n",
    "   X_train, _ = transform_features(train_data, log_transform=False, model_type='lgbm')\n",
    "   X_val, cat_features = transform_features(val_data, log_transform=False, model_type='lgbm')\n",
    "   _, X_val_norm, _ = normalize_train_test(X_train, X_val, method='none', \n",
    "                                         categorical_features=cat_features)\n",
    "   \n",
    "   # verify\n",
    "   assert X_eval_saved.equals(X_val_norm)\n",
    "   assert np.array_equal(y_eval_saved, val_data['eval_label'].values)\n",
    "   \n",
    "   return True\n",
    "\n",
    "validate_splits(splits, '../scripts/jobs/models/neg_study_dis_niter200_withint_with_int_5X_lgbm_0-3_20241113_235113')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the test data + everything from the dataset that was not in train and val\n",
    "test_data = splits['test']['full']\n",
    "\n",
    "# now get everything that was not in train and val\n",
    "train_val_data = pd.concat([splits['train']['full'], splits['val']['full']])\n",
    "train_val_ids = train_val_data['csc21_name'].unique()\n",
    "not_train_val_data = df_all_model[~df_all_model['csc21_name'].isin(train_val_ids)].copy()\n",
    "\n",
    "# check if test is IN not_train_val_data\n",
    "assert set(test_data['csc21_name'].unique()) <= set(not_train_val_data['csc21_name'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RA: 10:45:09.18751197\n",
      "Dec: -59:53:00.13780856\n"
     ]
    }
   ],
   "source": [
    "# Galactic coordinates from Townsley et al.\n",
    "l = 287.7 * u.degree\n",
    "b = -0.8 * u.degree\n",
    "\n",
    "# Convert to RA/Dec\n",
    "coord = SkyCoord(l=l, b=b, frame='galactic')\n",
    "radec = coord.icrs\n",
    "\n",
    "print(f\"RA: {radec.ra.to_string(unit=u.hour, sep=':')}\")\n",
    "print(f\"Dec: {radec.dec.to_string(unit=u.degree, sep=':')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the center of the Carina Complex region\n",
    "carina_center = radec\n",
    "\n",
    "# Create SkyCoord objects for all sources\n",
    "carina_source_coords = SkyCoord(ra=df_all_model['csc21_ra'].values * u.deg, dec=df_all_model['csc21_dec'].values * u.deg, frame='icrs')\n",
    "\n",
    "# Calculate separations\n",
    "carina_separations = carina_source_coords.separation(carina_center).to(u.arcmin)\n",
    "\n",
    "# Filter the dataframe\n",
    "df_all_model['separation_from_carina'] = carina_separations\n",
    "carina_sources_in_region = df_all_model[carina_separations <= 30 * u.arcmin].copy()\n",
    "carina_cscid_list = carina_sources_in_region['csc21_name'].str.replace('_', ' ').str.strip().unique().tolist()\n",
    "carina_sources_in_region['num_possible_counterparts'] = carina_sources_in_region.groupby('csc21_name')['gaia3_source_id'].transform('count')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_in_crit = get_match_label_simple(carina_sources_in_region, p_threshold=0.35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_in_crit_test_and_more = df_in_crit[df_in_crit['csc21_name'].isin(not_train_val_data['csc21_name'].unique())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3869"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_in_crit_test_and_more.csc21_name.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_performance_table(df):\n",
    "   \"\"\"create performance metrics and tabular summary\"\"\"\n",
    "   total_sources = df['csc21_name'].nunique()\n",
    "   \n",
    "   match_cases = {\n",
    "       'total_sources': total_sources,\n",
    "       'contains_match': {'count': 0, 'pct': 0},\n",
    "       'exact_match': {'count': 0, 'pct': 0}, \n",
    "       'different': {'count': 0, 'pct': 0},\n",
    "       'no_match': {'count': 0, 'pct': 0},\n",
    "       'multiple': {'count': 0, 'pct': 0}\n",
    "   }\n",
    "\n",
    "   for _, group in df.groupby('csc21_name'):\n",
    "       ml_matches = group[group['label'] == 1]\n",
    "       nway_matches = group[group['match_flag'] == 1]\n",
    "       \n",
    "       if len(nway_matches) == 1:\n",
    "           if nway_matches.index.isin(ml_matches.index).all():\n",
    "               match_cases['contains_match']['count'] += 1\n",
    "       if len(ml_matches) == 1 and len(nway_matches) == 1:\n",
    "           if ml_matches.index.equals(nway_matches.index):\n",
    "               match_cases['exact_match']['count'] += 1\n",
    "           else:\n",
    "               match_cases['different']['count'] += 1\n",
    "       elif len(ml_matches) == 0:\n",
    "           match_cases['no_match']['count'] += 1\n",
    "       elif len(ml_matches) > 1:\n",
    "           match_cases['multiple']['count'] += 1\n",
    "           \n",
    "   for key in match_cases:\n",
    "       if key != 'total_sources':\n",
    "           match_cases[key]['pct'] = (\n",
    "               match_cases[key]['count'] / total_sources * 100\n",
    "           )\n",
    "   \n",
    "   table = f\"\"\"\n",
    "Performance Summary (N={total_sources})\n",
    "=====================================\n",
    "Category          Count    Percent\n",
    "-------------------------------------\n",
    "Contains Match    {match_cases['contains_match']['count']:>5}     {match_cases['contains_match']['pct']:>6.1f}%\n",
    "Exact Match      {match_cases['exact_match']['count']:>5}     {match_cases['exact_match']['pct']:>6.1f}%\n",
    "Different Match  {match_cases['different']['count']:>5}     {match_cases['different']['pct']:>6.1f}%\n",
    "No Match         {match_cases['no_match']['count']:>5}     {match_cases['no_match']['pct']:>6.1f}%\n",
    "Multiple         {match_cases['multiple']['count']:>5}     {match_cases['multiple']['pct']:>6.1f}%\n",
    "\"\"\"\n",
    "   \n",
    "   return match_cases, table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Performance Summary (N=3869)\n",
      "=====================================\n",
      "Category          Count    Percent\n",
      "-------------------------------------\n",
      "Contains Match     2259       58.4%\n",
      "Exact Match       2207       57.0%\n",
      "Different Match     80        2.1%\n",
      "No Match          1527       39.5%\n",
      "Multiple            55        1.4%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stats, email = create_performance_table(df_in_crit_test_and_more)\n",
    "print(email)  # for quick review\n",
    "# or stats for detailed analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_performance_metrics(df):\n",
    "   \"\"\"compute match statistics between nway and ml model\"\"\"\n",
    "   metrics = {}\n",
    "   \n",
    "   # base counts\n",
    "   metrics['N_CSC'] = df['csc21_name'].nunique()\n",
    "   metrics['N_yNWAY'] = df[df['p_any'] > 0.5]['csc21_name'].nunique()\n",
    "   \n",
    "   # combined criteria using label column\n",
    "   ok_matches = (df['p_any'] > 0.5) & (df['label'] == 1)\n",
    "   metrics['N_OK'] = df[ok_matches]['csc21_name'].nunique()\n",
    "   \n",
    "   no_ml = (df['p_any'] > 0.5) & ~df.groupby('csc21_name')['label'].transform(any)\n",
    "   metrics['N_NoML'] = df[no_ml]['csc21_name'].nunique()\n",
    "   \n",
    "   flip = (df['p_any'] <= 0.5) & (df['label'] == 1)\n",
    "   metrics['N_FLIP'] = df[flip]['csc21_name'].nunique()\n",
    "   \n",
    "   none = (df['p_any'] <= 0.5) & ~df.groupby('csc21_name')['label'].transform(any)\n",
    "   metrics['N_NONE'] = df[none]['csc21_name'].nunique()\n",
    "   \n",
    "   # single/multiple match counts \n",
    "   ok_single = ok_matches & (df.groupby('csc21_name')['label'].transform(sum) == 1)\n",
    "   metrics['N_yNWAY+yMLeq1'] = df[ok_single]['csc21_name'].nunique()\n",
    "   metrics['N_yNWAY+yMLgt1'] = metrics['N_OK'] - metrics['N_yNWAY+yMLeq1']\n",
    "   \n",
    "   flip_single = flip & (df.groupby('csc21_name')['label'].transform(sum) == 1)\n",
    "   metrics['N_FLIPeq1'] = df[flip_single]['csc21_name'].nunique()\n",
    "   metrics['N_FLIPgt1'] = metrics['N_FLIP'] - metrics['N_FLIPeq1']\n",
    "\n",
    "   table = f\"\"\"\n",
    "N_CSC = {metrics['N_CSC']}\n",
    "N_yNWAY = {metrics['N_yNWAY']}\n",
    "N_OK = {metrics['N_OK']}\n",
    "N_NoML = {metrics['N_NoML']}\n",
    "N_FLIP = {metrics['N_FLIP']}\n",
    "N_NONE = {metrics['N_NONE']}\n",
    "N_yNWAY+yMLeq1 = {metrics['N_yNWAY+yMLeq1']}\n",
    "N_yNWAY+yMLgt1 = {metrics['N_yNWAY+yMLgt1']}\n",
    "N_FLIPeq1 = {metrics['N_FLIPeq1']}\n",
    "N_FLIPgt1 = {metrics['N_FLIPgt1']}\n",
    "\"\"\"\n",
    "   \n",
    "   return metrics, table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "N_CSC = 3869\n",
      "N_yNWAY = 2953\n",
      "N_OK = 2263\n",
      "N_NoML = 690\n",
      "N_FLIP = 79\n",
      "N_NONE = 837\n",
      "N_yNWAY+yMLeq1 = 2211\n",
      "N_yNWAY+yMLgt1 = 52\n",
      "N_FLIPeq1 = 76\n",
      "N_FLIPgt1 = 3\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_962181/103789065.py:23: FutureWarning: The provided callable <built-in function sum> is currently using SeriesGroupBy.sum. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"sum\" instead.\n",
      "  ok_single = ok_matches & (df.groupby('csc21_name')['label'].transform(sum) == 1)\n",
      "/tmp/ipykernel_962181/103789065.py:27: FutureWarning: The provided callable <built-in function sum> is currently using SeriesGroupBy.sum. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"sum\" instead.\n",
      "  flip_single = flip & (df.groupby('csc21_name')['label'].transform(sum) == 1)\n"
     ]
    }
   ],
   "source": [
    "stats_vk, email_vk = create_performance_metrics(df_in_crit_test_and_more)\n",
    "print(email_vk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_matches(df, df_all_stacks, threshold):\n",
    "   \"\"\"analyze match cases and output standardized csvs:\n",
    "   coup_nway1_mlX_tr{threshold}: no match by ML  \n",
    "   coup_nway1_ml1M_tr{threshold}: multiple matches by ML\n",
    "   coup_nway1_mlneq0_tr{threshold}: different match by ML\"\"\"\n",
    "   \n",
    "   output_cols = [\n",
    "       'csc21_name', 'csc21_ra', 'csc21_dec', 'min_theta_mean',\n",
    "       'detect_stack_id', 'gaia3_source_id', 'p_i', 'p_any', \n",
    "       'p_match_ind', 'separation', 'match_flag', 'label', 'phot_g_mean_mag',\n",
    "       'phot_bp_mean_mag', 'phot_rp_mean_mag', 'bp_rp'\n",
    "   ]\n",
    "   \n",
    "   result = {}\n",
    "   different_matches = []\n",
    "   no_counterparts = []\n",
    "   multiple_matches = []\n",
    "   \n",
    "   for csc_id, group in df.groupby('csc21_name'):\n",
    "       label_matches = group[group['label'] == 1]\n",
    "       nway_matches = group[group['match_flag'] == 1]\n",
    "       \n",
    "       if len(label_matches) == 1 and len(nway_matches) == 1:\n",
    "           if not label_matches.index.equals(nway_matches.index):\n",
    "               different_matches.append(group)\n",
    "       elif len(label_matches) == 0:\n",
    "           no_counterparts.append(group)\n",
    "       elif len(label_matches) > 1:\n",
    "           multiple_matches.append(group)\n",
    "\n",
    "   # map keys to filenames\n",
    "   filenames = {\n",
    "       'different_matches': f'cccp_nway1_mlneq0_tr{threshold}',\n",
    "       'no_counterparts': f'cccp_nway1_mlX_tr{threshold}',\n",
    "       'multiple_matches': f'cccp_nway1_ml1M_tr{threshold}'\n",
    "   }\n",
    "   \n",
    "   for key, data in zip(\n",
    "       ['different_matches', 'no_counterparts', 'multiple_matches'],\n",
    "       [different_matches, no_counterparts, multiple_matches]\n",
    "   ):\n",
    "       if data:\n",
    "           df_merged = (pd.concat(data)\n",
    "                       .merge(df_all_stacks[['name', 'detect_stack_id']],\n",
    "                              left_on='csc21_name', right_on='name', how='left')\n",
    "                       [output_cols])\n",
    "           df_merged.to_csv(f'outputs/{filenames[key]}.csv', index=False)\n",
    "           result[key] = df_merged\n",
    "\n",
    "   result['summary'] = {\n",
    "       'different_matches': len(set(result['different_matches']['csc21_name'])),\n",
    "       'no_counterparts': len(set(result['no_counterparts']['csc21_name'])),\n",
    "       'multiple_matches': len(set(result['multiple_matches']['csc21_name']))\n",
    "   }\n",
    "   \n",
    "   return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read vot to pandas ../data/all_stacks.vot\n",
    "from astropy.io.votable import parse_single_table\n",
    "\n",
    "# read vot to pandas\n",
    "table = parse_single_table('../data/all_stacks.vot')\n",
    "\n",
    "# recover column names\n",
    "df_all_stacks = table.to_table().to_pandas()\n",
    "df_all_stacks.columns = [col.name for col in table.fields]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_discrepant = analyze_matches(df_in_crit_test_and_more, df_all_stacks, threshold=0.35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'different_matches': 80, 'no_counterparts': 1527, 'multiple_matches': 55}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_discrepant['summary']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
