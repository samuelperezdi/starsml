{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from astropy.coordinates import SkyCoord\n",
    "from astropy import units as u\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "import os\n",
    "from src.classification import get_match_label_simple, get_match_label_advanced\n",
    "from src.data import get_data_basic_matches\n",
    "from sklearn.model_selection import train_test_split\n",
    "from src.utils import transform_features, normalize_train_test\n",
    "\n",
    "from joblib import load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the whole dataset with probabilities generated by the model\n",
    "df_all_model = pd.read_parquet('../scripts/nway_csc21_gaia3_full_neg_study_dis_niter200.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark_ids = load('../scripts/jobs/models/neg_study_dis_niter200_withint_with_int_5X_lgbm_0-3_20241113_235113/benchmark_ids.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Range 0-3: 30279 positives, 310020 negatives\n",
      "Range 0-3: 24223 positives, 245627 negatives\n",
      "Range 0-3: 19378 positives, 195135 negatives\n",
      "Range 0-3: 4845 positives, 50492 negatives\n",
      "Range 0-3: 6056 positives, 64393 negatives\n"
     ]
    }
   ],
   "source": [
    "def get_train_val_test_splits(df_all_model, benchmark_ids, range_offaxis='0-3', separation=1.3):\n",
    "   # get initial positives and split test set\n",
    "   df_pos, _ = get_data_basic_matches(df_all_model, range_offaxis, separation)\n",
    "   cscids = df_pos['csc21_name'].unique()\n",
    "   cscids_train_val, cscids_test = train_test_split(cscids, test_size=0.2, random_state=42)\n",
    "   \n",
    "   # get train/val split from filtered train_val data\n",
    "   df_train_val = df_all_model[df_all_model['csc21_name'].isin(cscids_train_val)]\n",
    "   train_pos, _ = get_data_basic_matches(df_train_val, range_offaxis, separation)\n",
    "   train_val_cscids = train_pos['csc21_name'].unique()\n",
    "   cscids_train, cscids_val = train_test_split(train_val_cscids, test_size=0.2, random_state=42)\n",
    "   \n",
    "   assert set(benchmark_ids) == set(cscids_test)\n",
    "   \n",
    "   # get final datasets\n",
    "   splits = {}\n",
    "   for name, ids in [('train', cscids_train), ('val', cscids_val), ('test', cscids_test)]:\n",
    "       data = df_all_model[df_all_model['csc21_name'].isin(ids)]\n",
    "       pos, neg = get_data_basic_matches(data, range_offaxis, separation)\n",
    "       splits[name] = {'pos': pos, 'neg': neg, 'full': data}\n",
    "       \n",
    "   return splits\n",
    "\n",
    "splits = get_train_val_test_splits(df_all_model, benchmark_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2j/bgzn208n7s93xhqxhxjy85nh0000gp/T/ipykernel_90084/694336655.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  val_data['eval_label'] = np.where(val_data['match_flag'] == 1, 1, 0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def validate_splits(splits, model_path):\n",
    "   \"\"\"validate train/val splits match saved model data\"\"\"\n",
    "   \n",
    "   # combine pos/neg sets\n",
    "   val_data = splits['val']['full']\n",
    "   train_data = splits['train']['full']\n",
    "   \n",
    "   # load saved validation data\n",
    "   X_eval_saved = load(os.path.join(model_path, 'X_eval.joblib'))\n",
    "   y_eval_saved = load(os.path.join(model_path, 'y_eval.joblib'))\n",
    "   \n",
    "   # prepare validation data\n",
    "   val_data['eval_label'] = np.where(val_data['match_flag'] == 1, 1, 0)\n",
    "   \n",
    "   # preprocess\n",
    "   X_train, _ = transform_features(train_data, log_transform=False, model_type='lgbm')\n",
    "   X_val, cat_features = transform_features(val_data, log_transform=False, model_type='lgbm')\n",
    "   _, X_val_norm, _ = normalize_train_test(X_train, X_val, method='none', \n",
    "                                         categorical_features=cat_features)\n",
    "   \n",
    "   # verify\n",
    "   assert X_eval_saved.equals(X_val_norm)\n",
    "   assert np.array_equal(y_eval_saved, val_data['eval_label'].values)\n",
    "   \n",
    "   return True\n",
    "\n",
    "validate_splits(splits, '../scripts/jobs/models/neg_study_dis_niter200_withint_with_int_5X_lgbm_0-3_20241113_235113')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the test data + everything from the dataset that was not in train and val\n",
    "test_data = splits['test']['full']\n",
    "\n",
    "# now get everything that was not in train and val\n",
    "train_val_data = pd.concat([splits['train']['full'], splits['val']['full']])\n",
    "train_val_ids = train_val_data['csc21_name'].unique()\n",
    "not_train_val_data = df_all_model[~df_all_model['csc21_name'].isin(train_val_ids)].copy()\n",
    "\n",
    "# check if test is IN not_train_val_data\n",
    "assert set(test_data['csc21_name'].unique()) <= set(not_train_val_data['csc21_name'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RA: 10:45:09.18751197\n",
      "Dec: -59:53:00.13780856\n"
     ]
    }
   ],
   "source": [
    "# Galactic coordinates from Townsley et al.\n",
    "l = 287.7 * u.degree\n",
    "b = -0.8 * u.degree\n",
    "\n",
    "# Convert to RA/Dec\n",
    "coord = SkyCoord(l=l, b=b, frame='galactic')\n",
    "radec = coord.icrs\n",
    "\n",
    "print(f\"RA: {radec.ra.to_string(unit=u.hour, sep=':')}\")\n",
    "print(f\"Dec: {radec.dec.to_string(unit=u.degree, sep=':')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the center of the Carina Complex region\n",
    "carina_center = radec\n",
    "\n",
    "# Create SkyCoord objects for all sources\n",
    "carina_source_coords = SkyCoord(ra=df_all_model['csc21_ra'].values * u.deg, dec=df_all_model['csc21_dec'].values * u.deg, frame='icrs')\n",
    "\n",
    "# Calculate separations\n",
    "carina_separations = carina_source_coords.separation(carina_center).to(u.arcmin)\n",
    "\n",
    "# Filter the dataframe\n",
    "df_all_model['separation_from_carina'] = carina_separations\n",
    "carina_sources_in_region = df_all_model[carina_separations <= 30 * u.arcmin].copy()\n",
    "carina_cscid_list = carina_sources_in_region['csc21_name'].str.replace('_', ' ').str.strip().unique().tolist()\n",
    "carina_sources_in_region['num_possible_counterparts'] = carina_sources_in_region.groupby('csc21_name')['gaia3_source_id'].transform('count')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_threshold = 0.44\n",
    "chance_threshold = 0.466\n",
    "p_tr = chance_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_in_crit = get_match_label_advanced(carina_sources_in_region, p_threshold=p_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_in_crit_test_and_more = df_in_crit[df_in_crit['csc21_name'].isin(not_train_val_data['csc21_name'].unique())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_in_crit_test_and_more = df_in_crit_test_and_more[df_in_crit_test_and_more['min_theta_mean'] <= 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3869"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_in_crit_test_and_more.csc21_name.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_in_crit_test = df_in_crit_test_and_more[df_in_crit_test_and_more['csc21_name'].isin(test_data['csc21_name'].unique())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_performance_metrics(df, p_threshold=0.466):\n",
    "   \"\"\"compute match statistics between nway and ml model\"\"\"\n",
    "   metrics = {}\n",
    "   \n",
    "   # base counts\n",
    "   metrics['N_CSC'] = df['csc21_name'].nunique()\n",
    "   metrics['N_yNWAY'] = df[df['p_any'] > 0.5]['csc21_name'].nunique()\n",
    "   \n",
    "   # combined criteria using label column\n",
    "   ok_matches = (df['p_any'] > 0.5) & (df['label'] == 1) & (df['match_flag'] == 1)\n",
    "   ok_ids = df[ok_matches]['csc21_name'].unique()\n",
    "   metrics['N_OK'] = df[ok_matches]['csc21_name'].nunique()\n",
    "   \n",
    "   no_ml = (df['p_any'] > 0.5) & ~df.groupby('csc21_name')['label'].transform(any)\n",
    "   metrics['N_NoML'] = df[no_ml]['csc21_name'].nunique()\n",
    "   \n",
    "   # delete all csc_ids which have an ok match\n",
    "   not_ok_ids = df[~df['csc21_name'].isin(ok_ids)]['csc21_name'].unique()\n",
    "   ynway_flipml = df[df['csc21_name'].isin(not_ok_ids) & (df['p_any'] > 0.5) & (df['label'] == 1)]\n",
    "   metrics['N_yNWAY_FLIP'] = ynway_flipml['csc21_name'].nunique()\n",
    "   \n",
    "   flip = (df['p_any'] <= 0.5) & (df['label'] == 1)\n",
    "   metrics['N_FLIP'] = df[flip]['csc21_name'].nunique()\n",
    "   \n",
    "   none = (df['p_any'] <= 0.5) & ~df.groupby('csc21_name')['label'].transform(any)\n",
    "   metrics['N_NONE'] = df[none]['csc21_name'].nunique()\n",
    "   \n",
    "   # single/multiple match counts \n",
    "   ok_single = ok_matches & (df.groupby('csc21_name')['label'].transform(sum) == 1)\n",
    "   metrics['N_yNWAY+yMLeq1'] = df[ok_single]['csc21_name'].nunique()\n",
    "   metrics['N_yNWAY+yMLgt1'] = metrics['N_OK'] - metrics['N_yNWAY+yMLeq1']\n",
    "   \n",
    "   flip_single = flip & (df.groupby('csc21_name')['label'].transform(sum) == 1)\n",
    "   metrics['N_FLIPeq1'] = df[flip_single]['csc21_name'].nunique()\n",
    "   metrics['N_FLIPgt1'] = metrics['N_FLIP'] - metrics['N_FLIPeq1']\n",
    "\n",
    "   # For each Gaia candidate (gaia_id) that has at least one row with high p_match_ind,\n",
    "   # count it only if in all rows the candidate is outside the separation threshold.   \n",
    "   high_ml = df[df['p_match_ind'] > p_threshold]\n",
    "   gaia_flag = high_ml.groupby('gaia3_source_id').apply(lambda g: (g['separation'] > g['threshold_sep']).all())\n",
    "   print(high_ml['threshold_sep']) \n",
    "   print(gaia_flag.sum())\n",
    "   metrics['N_MLglobal'] = gaia_flag[gaia_flag].index.nunique()\n",
    "\n",
    "   table = f\"\"\"\n",
    "   N_CSC = {metrics['N_CSC']}\n",
    "   N_yNWAY = {metrics['N_yNWAY']}\n",
    "   N_OK = {metrics['N_OK']}\n",
    "   N_NoML = {metrics['N_NoML']}\n",
    "   N_yNWAY_FLIP = {metrics['N_yNWAY_FLIP']}\n",
    "   N_FLIP = {metrics['N_FLIP']}\n",
    "   N_NONE = {metrics['N_NONE']}\n",
    "   N_yNWAY+yMLeq1 = {metrics['N_yNWAY+yMLeq1']}\n",
    "   N_yNWAY+yMLgt1 = {metrics['N_yNWAY+yMLgt1']}\n",
    "   N_FLIPeq1 = {metrics['N_FLIPeq1']}\n",
    "   N_FLIPgt1 = {metrics['N_FLIPgt1']}\n",
    "   N_MLglobal = {metrics['N_MLglobal']}\n",
    "   \"\"\"\n",
    "\n",
    "   return metrics, table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2j/bgzn208n7s93xhqxhxjy85nh0000gp/T/ipykernel_90084/3442842732.py:29: FutureWarning: The provided callable <built-in function sum> is currently using SeriesGroupBy.sum. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"sum\" instead.\n",
      "  ok_single = ok_matches & (df.groupby('csc21_name')['label'].transform(sum) == 1)\n",
      "/var/folders/2j/bgzn208n7s93xhqxhxjy85nh0000gp/T/ipykernel_90084/3442842732.py:33: FutureWarning: The provided callable <built-in function sum> is currently using SeriesGroupBy.sum. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"sum\" instead.\n",
      "  flip_single = flip & (df.groupby('csc21_name')['label'].transform(sum) == 1)\n",
      "/var/folders/2j/bgzn208n7s93xhqxhxjy85nh0000gp/T/ipykernel_90084/3442842732.py:40: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  gaia_flag = high_ml.groupby('gaia3_source_id').apply(lambda g: (g['separation'] > g['threshold_sep']).all())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1288020    3\n",
      "1288025    3\n",
      "1288026    3\n",
      "1288029    3\n",
      "1288135    3\n",
      "          ..\n",
      "1383060    4\n",
      "1383061    4\n",
      "1383062    4\n",
      "1383151    5\n",
      "1383154    5\n",
      "Name: threshold_sep, Length: 8680, dtype: int64\n",
      "4467\n",
      "\n",
      "   N_CSC = 3869\n",
      "   N_yNWAY = 2953\n",
      "   N_OK = 1852\n",
      "   N_NoML = 972\n",
      "   N_yNWAY_FLIP = 129\n",
      "   N_FLIP = 116\n",
      "   N_NONE = 800\n",
      "   N_yNWAY+yMLeq1 = 1750\n",
      "   N_yNWAY+yMLgt1 = 102\n",
      "   N_FLIPeq1 = 103\n",
      "   N_FLIPgt1 = 13\n",
      "   N_MLglobal = 4467\n",
      "   \n"
     ]
    }
   ],
   "source": [
    "stats_vk, email_vk = create_performance_metrics(df_in_crit_test_and_more)\n",
    "print(email_vk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gaia_multiple_n(df):\n",
    "   \"\"\"count total gaia matches in multiple match cases\"\"\"\n",
    "   # get sources with multiple matches\n",
    "   ok_multiples = (df['p_any'] > 0.5) & (df.groupby('csc21_name')['label'].transform(sum) > 1)\n",
    "   flip_multiples = (df['p_any'] <= 0.5) & (df.groupby('csc21_name')['label'].transform(sum) > 1)\n",
    "\n",
    "   # count matches\n",
    "   n_ok_gaia = df[ok_multiples & (df['label'] == 1)]['gaia3_source_id'].nunique()\n",
    "   n_flip_gaia = df[flip_multiples & (df['label'] == 1)]['gaia3_source_id'].nunique()\n",
    "   \n",
    "   return {\n",
    "       'N_yNWAY+yMLgt1_gaia': n_ok_gaia,\n",
    "       'N_FLIPgt1_gaia': n_flip_gaia\n",
    "   }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1009187/3518964572.py:4: FutureWarning: The provided callable <built-in function sum> is currently using SeriesGroupBy.sum. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"sum\" instead.\n",
      "  ok_multiples = (df['p_any'] > 0.5) & (df.groupby('csc21_name')['label'].transform(sum) > 1)\n",
      "/tmp/ipykernel_1009187/3518964572.py:5: FutureWarning: The provided callable <built-in function sum> is currently using SeriesGroupBy.sum. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"sum\" instead.\n",
      "  flip_multiples = (df['p_any'] <= 0.5) & (df.groupby('csc21_name')['label'].transform(sum) > 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'N_yNWAY+yMLgt1_gaia': 278, 'N_FLIPgt1_gaia': 29}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_gaia_multiple_n(df_in_crit_test_and_more)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_match_cases(df, df_all_stacks, train_val_ids):\n",
    "    \"\"\"export csvs for each match case type\"\"\"\n",
    "    output_cols = [\n",
    "    'csc21_name', 'csc21_ra', 'csc21_dec', 'min_theta_mean',\n",
    "    'detect_stack_id', 'gaia3_source_id', 'p_i', 'p_any', \n",
    "    'p_match_ind', 'separation', 'match_flag', 'label',\n",
    "    'phot_g_mean_mag', 'phot_bp_mean_mag', 'phot_rp_mean_mag', 'bp_rp'\n",
    "   ]\n",
    "\n",
    "    # initialize cases\n",
    "    N_yNWAY = []\n",
    "    N_OK = []\n",
    "    N_NoML = [] \n",
    "    N_FLIP = []\n",
    "    N_NONE = []\n",
    "\n",
    "    for csc_id, group in df.groupby('csc21_name'):\n",
    "        nway_confident = group['p_any'].max() > 0.5\n",
    "        ml_matches = group[group['label'] == 1]\n",
    "       \n",
    "        if nway_confident:\n",
    "            N_yNWAY.append(group)\n",
    "            # check if the match_flag==1 is also label ==1\n",
    "            if len(ml_matches) > 0 and (ml_matches['match_flag'] == 1).any():\n",
    "                N_OK.append(group)\n",
    "            elif len(ml_matches) == 0:\n",
    "                N_NoML.append(group)\n",
    "            elif (ml_matches['match_flag'] != 1).all():\n",
    "                N_FLIP.append(group)\n",
    "        elif len(ml_matches) == 0:\n",
    "            N_NONE.append(group)\n",
    "   \n",
    "    # save cases to csv\n",
    "    cases = {\n",
    "        'N_yNWAY': N_yNWAY,\n",
    "        'N_OK': N_OK,\n",
    "        'N_NoML': N_NoML,\n",
    "        'N_FLIP': N_FLIP,\n",
    "        'N_NONE': N_NONE\n",
    "    }\n",
    "\n",
    "    for case_name, case_data in cases.items():\n",
    "        if case_data:\n",
    "            df_case = (pd.concat(case_data)\n",
    "                        .merge(df_all_stacks[['name', 'detect_stack_id']], \n",
    "                            left_on='csc21_name', right_on='name', \n",
    "                            how='left')\n",
    "                        [output_cols])\n",
    "            os.makedirs(f'outputs/{p_tr}', exist_ok=True)\n",
    "            # delete train_val data\n",
    "            df_case = df_case[~df_case['csc21_name'].isin(train_val_ids)]\n",
    "            print(f\"Saving {case_name} with ({df_case['csc21_name'].nunique()}) csc21_names without train_val data\")\n",
    "            # save to csv\n",
    "            df_case.to_csv(f'outputs/{p_tr}/carina_{case_name}_trs{p_tr}.csv', index=False)\n",
    "            \n",
    "    return {k: len(set(pd.concat(v)['csc21_name'])) if v else 0 \n",
    "            for k,v in cases.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read vot to pandas ../data/all_stacks.vot\n",
    "from astropy.io.votable import parse_single_table\n",
    "\n",
    "# read vot to pandas\n",
    "table = parse_single_table('../data/all_stacks.vot')\n",
    "\n",
    "# recover column names\n",
    "df_all_stacks = table.to_table().to_pandas()\n",
    "df_all_stacks.columns = [col.name for col in table.fields]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving N_yNWAY with (2953) csc21_names without train_val data\n",
      "Saving N_OK with (1852) csc21_names without train_val data\n",
      "Saving N_NoML with (972) csc21_names without train_val data\n",
      "Saving N_FLIP with (129) csc21_names without train_val data\n",
      "Saving N_NONE with (800) csc21_names without train_val data\n"
     ]
    }
   ],
   "source": [
    "result_discrepant = analyze_match_cases(df_in_crit_test_and_more, df_all_stacks, train_val_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'N_yNWAY': 2953, 'N_OK': 1852, 'N_NoML': 972, 'N_FLIP': 129, 'N_NONE': 800}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_discrepant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chandragaia",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
